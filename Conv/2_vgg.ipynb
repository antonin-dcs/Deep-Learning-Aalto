{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f2b11aa8f0d0377563333bd78493751",
     "grade": false,
     "grade_id": "cell-e5b565cc4aae8e7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## FashionMNIST dataset\n",
    "\n",
    "Let us use the FashionMNIST dataset. It consists of 60,000 training images of 10 classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9fb758b86d03e9884930cd772a48671",
     "grade": false,
     "grade_id": "cell-8b0fded08998282c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='clothes_dataset', train=True, download=False, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root='clothes_dataset', train=False, download=False, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6cde19253d8a93916505d95820bd979",
     "grade": false,
     "grade_id": "cell-4ab9d042e4edcd54",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# VGG-style network\n",
    "\n",
    "Let us now define a convolution neural network with an architecture inspired by the [VGG-net](https://arxiv.org/abs/1409.1556).\n",
    "\n",
    "The architecture:\n",
    "- A block of three convolutional layers with:\n",
    "    - 3x3 kernel\n",
    "    - 20 output channels\n",
    "    - one pixel zero-pading on both sides\n",
    "    - 2d batch normalization after each convolutional layer\n",
    "    - ReLU nonlinearity after each 2d batch normalization layer\n",
    "- Max pooling layer with 2x2 kernel and stride 2.\n",
    "- A block of three convolutional layers with:\n",
    "    - 3x3 kernel\n",
    "    - 40 output channels\n",
    "    - one pixel zero-pading on both sides\n",
    "    - 2d batch normalization after each convolutional layer\n",
    "    - ReLU nonlinearity after each 2d batch normalization layer\n",
    "- Max pooling layer with 2x2 kernel and stride 2.\n",
    "- One convolutional layer with:\n",
    "    - 3x3 kernel\n",
    "    - 60 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- One convolutional layer with:\n",
    "    - 1x1 kernel\n",
    "    - 40 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- One convolutional layer with:\n",
    "    - 1x1 kernel\n",
    "    - 20 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- Global average pooling (compute the average value of each channel across all the input locations):\n",
    "    - 5x5 kernel (the input of the layer should be 5x5)\n",
    "- A fully-connected layer with 10 outputs (no nonlinearity)\n",
    "\n",
    "Notes:\n",
    "* Batch normalization is expected to be right after a convolutional layer, before nonlinearity.\n",
    "* We recommend that you check the number of modules with trainable parameters in your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c551737d0b27771d2082020b3824083",
     "grade": false,
     "grade_id": "cell-958d9ce586a51bd3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__()\n",
    "        #first block of 3 convolutional layer\n",
    "        self.conv11=nn.Conv2d(1,20,3,padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(20) \n",
    "        self.conv12=nn.Conv2d(20,20,3,padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(20) \n",
    "        self.conv13=nn.Conv2d(20,20,3,padding=1)\n",
    "        self.bn13 = nn.BatchNorm2d(20) \n",
    "        \n",
    "        #second block of 3 conv. layer\n",
    "        self.conv21=nn.Conv2d(20,40,3,padding=1)\n",
    "        self.bn21 = nn.BatchNorm2d(40) \n",
    "        self.conv22=nn.Conv2d(40,40,3,padding=1)\n",
    "        self.bn22 = nn.BatchNorm2d(40) \n",
    "        self.conv23=nn.Conv2d(40,40,3,padding=1)\n",
    "        self.bn23=nn.BatchNorm2d(40)\n",
    "        \n",
    "        # 1 conv layer\n",
    "        self.conv3=nn.Conv2d(40,60,3)\n",
    "        self.bn3 = nn.BatchNorm2d(60) \n",
    "        \n",
    "        #1 conv layer\n",
    "        self.conv4=nn.Conv2d(60,40,1)\n",
    "        self.bn4 = nn.BatchNorm2d(40) \n",
    "        \n",
    "        #1 conv layer\n",
    "        self.conv5=nn.Conv2d(40,20,1)\n",
    "        self.bn5 = nn.BatchNorm2d(20) \n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(20,10)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "          verbose: True if you want to print the shapes of the intermediate variables.\n",
    "\n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        # First Block\n",
    "        x = F.relu(self.bn11(self.conv11(x)))\n",
    "        x = F.relu(self.bn12(self.conv12(x)))\n",
    "        x = F.relu(self.bn13(self.conv13(x)))\n",
    "        x = F.max_pool2d(x, (2, 2),stride=2)\n",
    "        if verbose: print(f\"After Block 1: {x.shape}\")\n",
    "\n",
    "        # --- Second Block ---\n",
    "        x = F.relu(self.bn21(self.conv21(x)))\n",
    "        x = F.relu(self.bn22(self.conv22(x)))\n",
    "        x = F.relu(self.bn23(self.conv23(x)))\n",
    "        x = F.max_pool2d(x, (2, 2),stride=2)\n",
    "        if verbose: print(f\"After Block 2: {x.shape}\")\n",
    "\n",
    "        # --- Remaining Convolutions ---\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        if verbose: print(f\"After Block 3 & 4 & 5: {x.shape}\")\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        x = F.avg_pool2d(x, (5, 5))\n",
    "        x = torch.flatten(x, 1) \n",
    "        if verbose: print(f\"Before Linear: {x.shape}\")\n",
    "        \n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd755dd7c2d686a805e52ee83f3bcc55",
     "grade": false,
     "grade_id": "cell-e9e9a9dcda247c96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([32, 1, 28, 28])\n",
      "After Block 1: torch.Size([32, 20, 14, 14])\n",
      "After Block 2: torch.Size([32, 40, 7, 7])\n",
      "After Block 3 & 4 & 5: torch.Size([32, 20, 5, 5])\n",
      "Before Linear: torch.Size([32, 20])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_VGGNet_shapes():\n",
    "    net = VGGNet()\n",
    "    net.to(device)\n",
    "\n",
    "    # Feed a batch of images from the training data to test the network\n",
    "    with torch.no_grad():\n",
    "        images, labels = next(iter(trainloader))\n",
    "        images = images.to(device)\n",
    "        print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "        y = net(images, verbose=True)\n",
    "        assert y.shape == torch.Size([trainloader.batch_size, 10]), f\"Bad y.shape: {y.shape}\"\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "test_VGGNet_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "000d838e39022681381a8cf54d848126",
     "grade": true,
     "grade_id": "test_VGGNet",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "[(10,), (10, 20), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20, 1, 3, 3), (20, 20, 3, 3), (20, 20, 3, 3), (20, 40, 1, 1), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40, 20, 3, 3), (40, 40, 3, 3), (40, 40, 3, 3), (40, 60, 1, 1), (60,), (60,), (60,), (60, 40, 3, 3)]\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Check the number of layers\n",
    "def test_vgg_layers():\n",
    "    net = VGGNet()\n",
    "\n",
    "    # get gradients for parameters in forward path\n",
    "    net.zero_grad()\n",
    "    x = torch.randn(1, 1, 28, 28)\n",
    "    outputs = net(x)\n",
    "    outputs[0,0].backward()\n",
    "\n",
    "    n_conv_layers = sum(1 for module in net.modules()\n",
    "                        if isinstance(module, nn.Conv2d) and next(module.parameters()).grad is not None)\n",
    "    assert n_conv_layers == 9, f\"Wrong number of convolutional layers ({n_conv_layers})\"\n",
    "\n",
    "    n_bn_layers = sum(1 for module in net.modules()\n",
    "                      if isinstance(module, nn.BatchNorm2d) and next(module.parameters()).grad is not None)\n",
    "    assert n_bn_layers == 9, f\"Wrong number of batch norm layers ({n_bn_layers})\"\n",
    "\n",
    "    n_linear_layers = sum(1 for module in net.modules()\n",
    "                          if isinstance(module, nn.Linear) and next(module.parameters()).grad is not None)\n",
    "    assert n_linear_layers == 1, f\"Wrong number of linear layers ({n_linear_layers})\"\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "def test_vgg_net():\n",
    "    net = VGGNet()\n",
    "\n",
    "    # get gradients for parameters in forward path\n",
    "    net.zero_grad()\n",
    "    x = torch.randn(1, 1, 28, 28)\n",
    "    outputs = net(x)\n",
    "    outputs[0,0].backward()\n",
    "\n",
    "    parameter_shapes = sorted(tuple(p.shape) for p in net.parameters() if p.grad is not None)\n",
    "    print(parameter_shapes)\n",
    "    expected = [\n",
    "        (10,), (10, 20), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,),\n",
    "        (20,), (20,), (20,), (20, 1, 3, 3), (20, 20, 3, 3), (20, 20, 3, 3), (20, 40, 1, 1),\n",
    "        (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,),\n",
    "        (40, 20, 3, 3), (40, 40, 3, 3), (40, 40, 3, 3), (40, 60, 1, 1), (60,), (60,), (60,),\n",
    "        (60, 40, 3, 3)]\n",
    "    assert parameter_shapes == expected, \"Wrong number of training parameters.\"\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "test_vgg_layers()\n",
    "test_vgg_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c87ccb8eb839f919438ec33b6d8f5e3b",
     "grade": false,
     "grade_id": "cell-6c5c6ddc6d0312e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f83e3828402226248c665aa6b1f49a8",
     "grade": false,
     "grade_id": "cell-9e3a0480727aec61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70e1b87d5ab693181bbc4ecfc21b26c8",
     "grade": false,
     "grade_id": "cell-d168751b85ea2490",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Your task is to implement the training loop. The recommended hyperparameters:\n",
    "* Adam optimizer with learning rate 0.01.\n",
    "* Cross-entropy loss. Note that we did not use softmax nonlinearity in the final layer of our network. Therefore, we need to use a loss function with log_softmax implemented, such as [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss).\n",
    "* Number of epochs: 10\n",
    "\n",
    "We recommend you to use function `compute_accuracy()` defined above to track the accaracy during training. The test accuracy should be above 0.89.\n",
    "\n",
    "**Note: function `compute_accuracy()` sets the network into the evaluation mode which changes the way the batch statistics are computed in batch normalization. You need to set the network into the training mode (by calling `net.train()`) when you want to perform training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db3a9615921b7a80d333475aa66ae69b",
     "grade": false,
     "grade_id": "cell-d5bf19391acb3661",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = VGGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6270848f5387bf01aba9bb5f50303a78",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the training loop\n",
      "epochs: 0\n",
      "epochs: 1\n",
      "epochs: 2\n",
      "epochs: 3\n",
      "epochs: 4\n",
      "epochs: 5\n",
      "epochs: 6\n",
      "epochs: 7\n",
      "epochs: 8\n",
      "epochs: 9\n",
      "training_finished\n",
      "final accuracy : 0.9254\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop in this cell\n",
    "if not skip_training:\n",
    "    n_epochs=10\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optim=torch.optim.Adam(params=net.parameters(),lr=.01)\n",
    "    print(\"start of the training loop\")\n",
    "    net.train()\n",
    "    for n in range(n_epochs):\n",
    "        # accuracy=compute_accuracy(net,testloader)\n",
    "        # print(f'accuracy : {accuracy}, epoch : {n+1}')\n",
    "        # net.train()\n",
    "        print(f'epochs: {n}')\n",
    "        for images,labels in trainloader:\n",
    "            optim.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs=net(images)\n",
    "            \n",
    "            loss=criterion(outputs,labels)\n",
    "            loss.backward() #compute the gradients\n",
    "            optim.step() #mets Ã  jour les poids de l'optimiseur\n",
    "            \n",
    "    \n",
    "    print(\"training_finished\")\n",
    "    accuracy=compute_accuracy(net,testloader)\n",
    "    print(f'final accuracy : {accuracy}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "torch.save(net.state_dict(),f=\"model_VGG_conv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63bba11d24ab5d7fd716a8930b4f1bc8",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the VGG net on the test images:  0.925\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print(f'Accuracy of the VGG net on the test images: {accuracy: .3f}')\n",
    "assert accuracy > 0.89, 'Poor accuracy'\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:  Ankle boot   Pullover    Trouser    Trouser      Shirt\n",
      "Predictions:   Ankle boot   Pullover    Trouser    Trouser      Shirt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the network to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# 1. Grab a batch of data\n",
    "with torch.no_grad():\n",
    "    images, labels = next(iter(testloader))\n",
    "    \n",
    "    # 2. Compute predictions\n",
    "    images_dev = images.to(device)\n",
    "    outputs = net(images_dev)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# 3. Plot the first 5 images using Matplotlib\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    # PyTorch tensors are (C, H, W), Matplotlib needs (H, W, C)\n",
    "    img = images[i].numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # If your images were normalized, you might need to un-normalize them here\n",
    "    # img = img * std + mean \n",
    "    \n",
    "    axes[i].imshow(img.squeeze(), cmap='gray' if img.shape[2] == 1 else None)\n",
    "    axes[i].set_title(f\"Pred: {classes[predicted[i]]}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 4. Print the text summary\n",
    "print('Ground truth: ', ' '.join('%10s' % classes[labels[j]] for j in range(5)))\n",
    "print('Predictions:  ', ' '.join('%10s' % classes[predicted[j]] for j in range(5)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
